{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a571134-1e5f-42bb-8c6c-cf1a3eb8d0b1",
   "metadata": {},
   "source": [
    "# Мониторинг звуковой среды с помощью предобученной модели\n",
    "\n",
    "В этом проекте решается задача мониторинга звуковой среды (природные и техногенные звуки) с использованием предобученной аудио‑модели и датасета ESC‑50. Цель — показать прототип системы, которая по коротким аудиозаписям определяет типы звуков (птицы, дождь, транспорт и т.п.) и может быть использована для отслеживания изменения звуковой экосистемы во времени.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77812b73-2f46-4f00-8dc8-9f94155253ea",
   "metadata": {},
   "source": [
    "В современных городах и природных территориях важно отслеживать изменения звуковой среды: снижение активности птиц, рост техногенного шума, появление аномальных звуков. Ручной анализ аудиозаписей трудозатратен, поэтому полезен автоматизированный инструмент, который по аудиофайлам оценивает, преобладают ли природные или техногенные звуки.\n",
    "\n",
    "В этом прототипе:\n",
    "- «natural» — звуки природы (пение птиц, гром, дождь, ветер, насекомые и т.д.).\n",
    "- «industrial» — техногенные звуки (бытовая техника, транспорт, сирены и т.п.).\n",
    "\n",
    "Система может использоваться экологами, исследователями и городскими службами как вспомогательный инструмент мониторинга экосистемы по звуку."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a697426-a70b-4f0b-b782-09b48ccafeff",
   "metadata": {},
   "source": [
    "# 1. Установка и импорты "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8b1d68d-f02d-408a-a1a9-0e426c25a13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install librosa soundfile torchaudio torch torchvision --quiet\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import torchaudio\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02971565-7b14-4092-8afc-e1255d0b854e",
   "metadata": {},
   "source": [
    "# 2. Загрузка датасета ESC‑50 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9bea1d-605b-4c60-8b52-0a44e8f085de",
   "metadata": {},
   "source": [
    "Для демонстрации используется открытый датасет ESC‑50, содержащий 2000 аудиозаписей по 5 секунд в 50 классах звуков окружающей среды (животные, природные явления, бытовые и городские звуки). Из него формируется поднабор из двух групп:\n",
    "- природные звуки (`natural`);\n",
    "- техногенные/индустриальные звуки (`industrial`).\n",
    "\n",
    "По колонке `category` в `esc50.csv` классам задаются группы, после чего остаётся 320 записей: 200 природных и 120 техногенных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b545da4-3c12-4181-a8b8-5c46498e0de1",
   "metadata": {},
   "source": [
    "## Загрузка датасета ESC‑50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa75e476-ed9c-4abf-9368-4764819b8003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Скачиваю ESC-50...\n",
      "Готово, датасет в папке: data/ESC-50\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import requests\n",
    "\n",
    "DATA_ROOT = \"data\"\n",
    "ESC50_DIR = os.path.join(DATA_ROOT, \"ESC-50\")\n",
    "os.makedirs(DATA_ROOT, exist_ok=True)\n",
    "\n",
    "zip_url = \"https://github.com/karolpiczak/ESC-50/archive/master.zip\"\n",
    "zip_path = os.path.join(DATA_ROOT, \"ESC-50.zip\")\n",
    "\n",
    "if not os.path.exists(ESC50_DIR):\n",
    "    r = requests.get(zip_url)\n",
    "    with open(zip_path, \"wb\") as f:\n",
    "        f.write(r.content)\n",
    "\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(DATA_ROOT)\n",
    "\n",
    "    # Переименуем распакованную папку в удобное имя\n",
    "    os.rename(os.path.join(DATA_ROOT, \"ESC-50-master\"), ESC50_DIR)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce7540dd-b133-4ba1-966f-c7313884ba65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>fold</th>\n",
       "      <th>target</th>\n",
       "      <th>category</th>\n",
       "      <th>esc10</th>\n",
       "      <th>src_file</th>\n",
       "      <th>take</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-100032-A-0.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>dog</td>\n",
       "      <td>True</td>\n",
       "      <td>100032</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-100038-A-14.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>chirping_birds</td>\n",
       "      <td>False</td>\n",
       "      <td>100038</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-100210-A-36.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>vacuum_cleaner</td>\n",
       "      <td>False</td>\n",
       "      <td>100210</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-100210-B-36.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>vacuum_cleaner</td>\n",
       "      <td>False</td>\n",
       "      <td>100210</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1-101296-A-19.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>thunderstorm</td>\n",
       "      <td>False</td>\n",
       "      <td>101296</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename  fold  target        category  esc10  src_file take\n",
       "0   1-100032-A-0.wav     1       0             dog   True    100032    A\n",
       "1  1-100038-A-14.wav     1      14  chirping_birds  False    100038    A\n",
       "2  1-100210-A-36.wav     1      36  vacuum_cleaner  False    100210    A\n",
       "3  1-100210-B-36.wav     1      36  vacuum_cleaner  False    100210    B\n",
       "4  1-101296-A-19.wav     1      19    thunderstorm  False    101296    A"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = \"/Users/yaroslavbaev/Desktop/miphi/data/ESC-50\"\n",
    "\n",
    "meta_path = os.path.join(DATA_DIR, \"meta\", \"esc50.csv\")\n",
    "meta = pd.read_csv(meta_path)\n",
    "meta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138d8423-b4a7-4789-b736-43e5e5c1e547",
   "metadata": {},
   "source": [
    "# 3. Формирование подзадачи: природные vs техногенные звуки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950c98d3-c544-4357-a55c-d553898bfed0",
   "metadata": {},
   "source": [
    "## Формирование групп классов: природные и техногенные звуки\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "776a8519-b9a2-4309-b91c-8c32577814e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "group\n",
       "other         1680\n",
       "natural        200\n",
       "industrial     120\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "natural_classes = [\n",
    "    \"chirping_birds\",\n",
    "    \"thunderstorm\",\n",
    "    \"rain\",\n",
    "    \"wind\",\n",
    "    \"crickets\"\n",
    "]\n",
    "\n",
    "industrial_classes = [\n",
    "    \"vacuum_cleaner\",\n",
    "    \"car_horn\",\n",
    "    \"siren\",\n",
    "    \"jackhammer\",\n",
    "    \"engine_idling\"\n",
    "]\n",
    "\n",
    "meta[\"group\"] = meta[\"category\"].apply(\n",
    "    lambda c: \"natural\" if c in natural_classes\n",
    "    else (\"industrial\" if c in industrial_classes else \"other\")\n",
    ")\n",
    "\n",
    "meta[\"group\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e57e5e8-870e-44e8-b0e3-9fc8bcd64a43",
   "metadata": {},
   "source": [
    "## Выбор поднабора данных для мониторинга звуковой среды\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57052629-7f71-4e37-a997-3beece414e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320,\n",
       " group\n",
       " natural       200\n",
       " industrial    120\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_subset = meta[meta[\"group\"].isin([\"natural\", \"industrial\"])].reset_index(drop=True)\n",
    "len(meta_subset), meta_subset[\"group\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ba76a5-d641-49d8-a239-36bcafcec358",
   "metadata": {},
   "source": [
    "## 4. Предобученная аудио‑модель из Transformers (Hugging Face)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650ca366-8624-4203-8de5-198b3890b072",
   "metadata": {},
   "source": [
    "Чтобы не обучать собственную нейросеть с нуля, используется предобученная аудио‑модель `MIT/ast-finetuned-audioset-10-10-0.4593`, обученная на большом датасете AudioSet. Модель принимает на вход сырое аудио и возвращает распределение вероятностей по 527 звуковым классам. Это позволяет использовать её как готовый «датчик» звукового окружения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "804619d7-ed4a-4c1a-8b1e-5df6f12cfc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers torchaudio --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8113b51-8f1d-4929-9a2f-c596768060b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25e586c4e3a14576b62ce0ac36adaa1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/297 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f5d5b794d09473d8bcaec7d3f4964d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd76d179d4dd45438fac5cdedd6fa59c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(527,\n",
       " [(0, 'Speech'),\n",
       "  (1, 'Male speech, man speaking'),\n",
       "  (2, 'Female speech, woman speaking'),\n",
       "  (3, 'Child speech, kid speaking'),\n",
       "  (4, 'Conversation')])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoProcessor, AutoModelForAudioClassification\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "model_name = \"MIT/ast-finetuned-audioset-10-10-0.4593\" \n",
    "processor = AutoProcessor.from_pretrained(model_name)\n",
    "audio_model = AutoModelForAudioClassification.from_pretrained(model_name).to(device)\n",
    "audio_model.eval()\n",
    "\n",
    "id2label = audio_model.config.id2label\n",
    "len(id2label), list(id2label.items())[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67294c10-f59f-4e08-a1c7-9c7ebde9f43d",
   "metadata": {},
   "source": [
    "На этом шаге определяется функция загрузки аудиофайла, приведения его к нужной частоте дискретизации и вызова предобученной модели. Модель возвращает вектор вероятностей по 527 классам, а также топ‑k наиболее вероятных классов, что позволяет интерпретировать тип звука."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c159d636-ea3d-49e3-bcf0-d7df51eaf90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "TARGET_SR = 16000  # под ast-модель\n",
    "\n",
    "def load_audio_waveform(path, sr=TARGET_SR):\n",
    "    y, orig_sr = librosa.load(path, sr=None)  # читать через librosa\n",
    "    if orig_sr != sr:\n",
    "        y = librosa.resample(y, orig_sr=orig_sr, target_sr=sr)\n",
    "    return y  #1D numpy array (T, )\n",
    "\n",
    "def predict_audio_labels(path, top_k=5):\n",
    "    waveform = load_audio_waveform(path, sr=TARGET_SR)\n",
    "    inputs = processor(waveform, sampling_rate=TARGET_SR, return_tensors=\"pt\")\n",
    "    inputs = {k: torch.tensor(v).to(device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = audio_model(**inputs)\n",
    "        probs = torch.softmax(outputs.logits, dim=-1)[0].cpu().numpy()\n",
    "\n",
    "    top_idx = probs.argsort()[::-1][:top_k]\n",
    "    results = [(id2label[int(i)], float(probs[i])) for i in top_idx]\n",
    "    return results, probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "addb7853-e873-49e5-add7-7ac696098aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-100038-A-14.wav -> chirping_birds -> natural\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q0/29fzx5zj31g3hxygfclyh8sr0000gn/T/ipykernel_74945/3558672398.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs = {k: torch.tensor(v).to(device) for k, v in inputs.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bird: 0.256\n",
      "Bird vocalization, bird call, bird song: 0.230\n",
      "Owl: 0.169\n",
      "Chirp, tweet: 0.135\n",
      "Animal: 0.035\n",
      "Размер вектора вероятностей: (527,)\n"
     ]
    }
   ],
   "source": [
    "example_row = meta_subset.iloc[0]\n",
    "audio_path = os.path.join(ESC50_DIR, \"audio\", example_row[\"filename\"])\n",
    "print(example_row[\"filename\"], \"->\", example_row[\"category\"], \"->\", example_row[\"group\"])\n",
    "\n",
    "top_preds, probs_vec = predict_audio_labels(audio_path, top_k=5)\n",
    "for label, p in top_preds:\n",
    "    print(f\"{label}: {p:.3f}\")\n",
    "print(\"Размер вектора вероятностей:\", probs_vec.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f451b660-8eb2-4715-8502-bd2a903eac9f",
   "metadata": {},
   "source": [
    "Результат для примера с категорией `chirping_birds` показывает, что предобученная модель корректно распознаёт птичьи звуки (в топ‑классах присутствуют категории, связанные с птицами). Это подтверждает, что модель подходит в качестве основы для мониторинга звуковой экосистемы."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e93140-bfa3-4e1a-9112-091e16d2bb9d",
   "metadata": {},
   "source": [
    "# 5. Признаки и классификатор"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7157ef5d-cad8-4335-b7e9-50a056722cea",
   "metadata": {},
   "source": [
    "\n",
    "Вектор вероятностей по 527 классам, который возвращает предобученная модель, используется как признаковое представление каждого аудиофайла. На этих признаках обучается лёгкий линейный классификатор (логистическая регрессия), решающий задачу: `natural` vs `industrial`. Это позволяет построить прикладное решение для мониторинга звуковой среды без обучения тяжёлой нейросети.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c905919e-d345-41b5-a88d-ea05e6f3b9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q0/29fzx5zj31g3hxygfclyh8sr0000gn/T/ipykernel_74945/3558672398.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs = {k: torch.tensor(v).to(device) for k, v in inputs.items()}\n",
      "100%|██████████| 100/100 [00:49<00:00,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  industrial       0.89      0.67      0.76        12\n",
      "     natural       0.81      0.94      0.87        18\n",
      "\n",
      "    accuracy                           0.83        30\n",
      "   macro avg       0.85      0.81      0.82        30\n",
      "weighted avg       0.84      0.83      0.83        30\n",
      "\n",
      "[[ 8  4]\n",
      " [ 1 17]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "N_SAMPLES = 100  # можно увеличить до 200–300, если по времени ок\n",
    "subset_small = meta_subset.sample(N_SAMPLES, random_state=42).reset_index(drop=True)\n",
    "\n",
    "features = []\n",
    "labels_group = []\n",
    "filenames = []\n",
    "\n",
    "for idx, row in tqdm.tqdm(subset_small.iterrows(), total=len(subset_small)):\n",
    "    path = os.path.join(ESC50_DIR, \"audio\", row[\"filename\"])\n",
    "    _, probs_vec = predict_audio_labels(path, top_k=5)\n",
    "    features.append(probs_vec)\n",
    "    labels_group.append(row[\"group\"])\n",
    "    filenames.append(row[\"filename\"])\n",
    "\n",
    "features = np.stack(features)  # (N, 527)\n",
    "\n",
    "X = features\n",
    "y = np.array([1 if g == \"natural\" else 0 for g in labels_group])  # 1=natural, 0=industrial\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=[\"industrial\", \"natural\"]))\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff786160-5c8a-43eb-8cd3-35c2439ee6a8",
   "metadata": {},
   "source": [
    "Полученные метрики (precision, recall, F1‑мера) для классов `natural` и `industrial` показывают, что даже простой линейный классификатор на предобученных признаках способен различать природные и техногенные звуки. Это демонстрирует, что комбинация предобученной модели и лёгкого классификатора уже даёт рабочий прототип системы мониторинга звуковой экосистемы.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb96cb3-b888-45c8-b55f-48f0f9b0be1a",
   "metadata": {},
   "source": [
    "# 6. end‑to‑end сценарий"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce448dcb-9539-42e0-8bd8-199fc91a8318",
   "metadata": {},
   "source": [
    "На практике пользователь работает не с таблицей, а с отдельными аудиозаписями. Ниже показан end‑to‑end сценарий: на вход подаётся путь к аудиофайлу, система использует предобученную модель для извлечения признаков, затем применяет обученный классификатор и возвращает решение `natural` или `industrial` вместе с уверенностью модели и топ‑классами по AudioSet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08fb873b-abfb-44b2-8420-fe548e00c686",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q0/29fzx5zj31g3hxygfclyh8sr0000gn/T/ipykernel_74945/3558672398.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs = {k: torch.tensor(v).to(device) for k, v in inputs.items()}\n",
      "/var/folders/q0/29fzx5zj31g3hxygfclyh8sr0000gn/T/ipykernel_74945/3558672398.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs = {k: torch.tensor(v).to(device) for k, v in inputs.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Файл: 3-243726-A-43.wav\n",
      "Реальная группа: industrial\n",
      "Модель: natural (p=0.548)\n",
      "Топ-5 классов AST-модели:\n",
      "  Vehicle: 0.249\n",
      "  Speech: 0.105\n",
      "  Train: 0.099\n",
      "  Outside, urban or manmade: 0.070\n",
      "  Rail transport: 0.051\n"
     ]
    }
   ],
   "source": [
    "def classify_sound_business(path):\n",
    "    # Предсказания предобученной модели (признаки)\n",
    "    _, probs_vec = predict_audio_labels(path, top_k=5)\n",
    "    probs_vec = probs_vec.reshape(1, -1)\n",
    "\n",
    "    # Предсказание нашего классификатора\n",
    "    pred = clf.predict(probs_vec)[0]\n",
    "    proba = clf.predict_proba(probs_vec)[0][pred]\n",
    "\n",
    "    business_label = \"natural\" if pred == 1 else \"industrial\"\n",
    "\n",
    "    # Для интерпретации ещё раз получаем топ-5 классов AST-модели\n",
    "    top_labels, _ = predict_audio_labels(path, top_k=5)\n",
    "    return business_label, proba, top_labels\n",
    "\n",
    "# Пример использования на случайно выбранном файле из meta_subset\n",
    "test_row = meta_subset.sample(1, random_state=0).iloc[0]\n",
    "test_path = os.path.join(ESC50_DIR, \"audio\", test_row[\"filename\"])\n",
    "\n",
    "business_label, proba, top_labels = classify_sound_business(test_path)\n",
    "\n",
    "print(\"Файл:\", test_row[\"filename\"])\n",
    "print(\"Реальная группа:\", test_row[\"group\"])\n",
    "print(f\"Модель: {business_label} (p={proba:.3f})\")\n",
    "print(\"Топ-5 классов AST-модели:\")\n",
    "for label, p in top_labels:\n",
    "    print(f\"  {label}: {p:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d96850-60c1-4873-a80e-2459179ec679",
   "metadata": {},
   "source": [
    "Звук на этом файле относится к техногенным (industrial), но классификатор по предобученной модели решил, что это скорее «natural» с невысокой уверенностью 0.548.​\n",
    "\n",
    "При этом сама AST‑модель в топ‑классах видит транспорт, речь и городской/man‑made фон (vehicle, train, urban), то есть по сути правильно «чувствует» техногенную среду, просто линейный классификатор поверх её признаков в этом случае ошибся и перепутал группу. Все мы ошибаемся..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c3841e-99eb-460b-8b1d-25df159d5cc2",
   "metadata": {},
   "source": [
    "## 7. Выводы\n",
    "\n",
    "В рамках проектной работы реализован прототип системы мониторинга звуковой среды, который:\n",
    "- использует открытый датасет ESC‑50 для моделирования природных и техногенных звуков;\n",
    "- опирается на предобученную аудио‑модель `MIT/ast-finetuned-audioset-10-10-0.4593` без переобучения;\n",
    "- строит лёгкий классификатор для задачи `natural` vs `industrial` на признаках предобученной модели;\n",
    "- предоставляет end‑to‑end сценарий для классификации отдельного аудиофайла.\n",
    "\n",
    "Такое решение может быть расширено до реального мониторинга экосистемы: достаточно подключить реальные аудио‑датчики и регулярно обрабатывать записи, оценивая долю природных и техногенных звуков во времени.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
